[
    {
        "id": "google/gemma-2-2b-it-GGUF",
        "name": "gemma-2-2b-it-GGUF (Q6_K)",
        "type": "Gemma",
        "size": "2.15",
        "params": "2",
        "isDownloaded": false,
        "downloadUrl": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q6_K.gguf?download=true",
        "hfUrl": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF",
        "progress": 0,
        "filename": "gemma-2-2b-it-Q6_K.gguf",
        "isLocal": false,
        "info_url": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF",
        "defaultChatTemplate": {
            "bosToken": "<bos>",
            "eosToken": "<eos>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token -}}{%- if messages[0].role == 'system' -%}{%- set system_message = messages[0].content | trim + '\n\n' -%}{%- set messages = messages.slice(1) -%}{%- else -%}{%- set system_message = '' -%}{%- endif %}{%- for message in messages -%}{%- if (message.role == 'user') != (loop.index0 % 2 == 0) -%}{{- raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') -}}{%- endif -%}{%- if loop.index0 == 0 -%}{%- set content = system_message + message.content -%}{%- else -%}{%- set content = message.content -%}{%- endif -%}{%- if message.role == 'assistant' -%}{%- set role = 'model' -%}{%- else -%}{%- set role = message.role -%}{%- endif -%}{{- '<start_of_turn>' + role + '\n' + (content | trim) + '<end_of_turn>\n' -}}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<start_of_turn>model\n' -}}{%- endif -%}",
            "name": "gemmaIt",
            "addGenerationPrompt": true,
            "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
        },
        "chatTemplate": {
            "bosToken": "<bos>",
            "eosToken": "<eos>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token -}}{%- if messages[0].role == 'system' -%}{%- set system_message = messages[0].content | trim + '\n\n' -%}{%- set messages = messages.slice(1) -%}{%- else -%}{%- set system_message = '' -%}{%- endif %}{%- for message in messages -%}{%- if (message.role == 'user') != (loop.index0 % 2 == 0) -%}{{- raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') -}}{%- endif -%}{%- if loop.index0 == 0 -%}{%- set content = system_message + message.content -%}{%- else -%}{%- set content = message.content -%}{%- endif -%}{%- if message.role == 'assistant' -%}{%- set role = 'model' -%}{%- else -%}{%- set role = message.role -%}{%- endif -%}{{- '<start_of_turn>' + role + '\n' + (content | trim) + '<end_of_turn>\n' -}}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<start_of_turn>model\n' -}}{%- endif -%}",
            "name": "gemmaIt",
            "addGenerationPrompt": true,
            "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
        },
        "defaultCompletionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<end_of_turn>"
            ]
        },
        "completionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<end_of_turn>"
            ]
        }
    },
    {
        "id": "Phi-3.5-mini-instruct.Q4_K_M.gguf",
        "name": "Phi-3.5 mini 4k instruct (Q4_K_M)",
        "type": "Phi",
        "size": "2.39",
        "params": "3.8",
        "isDownloaded": false,
        "downloadUrl": "https://huggingface.co/QuantFactory/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct.Q4_K_M.gguf?download=true",
        "hfUrl": "https://huggingface.co/QuantFactory/Phi-3.5-mini-instruct-GGUF",
        "progress": 0,
        "filename": "Phi-3.5-mini-instruct.Q4_K_M.gguf",
        "isLocal": false,
        "info_url": "https://huggingface.co/QuantFactory/Phi-3.5-mini-instruct-GGUF",
        "defaultChatTemplate": {
            "bosToken": "<s>",
            "eosToken": "<|endoftext|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{%- for message in messages -%}{%- if message.role == 'system' -%}{{- '<|system|>\n' + message.content | trim + '<|end|>\n' -}}{%- elif message.role == 'user' -%}{{- '<|user|>\n' + message.content | trim + '<|end|>\n' -}}{%- elif message.role == 'assistant' -%}{{- '<|assistant|>\n' + message.content | trim + '<|end|>\n' -}}{%- endif -%}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<|assistant|>\n' -}}{%- else -%}{{- eos_token -}}{%- endif -%}",
            "name": "phi3",
            "addGenerationPrompt": true,
            "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
        },
        "chatTemplate": {
            "bosToken": "<s>",
            "eosToken": "<|endoftext|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{%- for message in messages -%}{%- if message.role == 'system' -%}{{- '<|system|>\n' + message.content | trim + '<|end|>\n' -}}{%- elif message.role == 'user' -%}{{- '<|user|>\n' + message.content | trim + '<|end|>\n' -}}{%- elif message.role == 'assistant' -%}{{- '<|assistant|>\n' + message.content | trim + '<|end|>\n' -}}{%- endif -%}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<|assistant|>\n' -}}{%- else -%}{{- eos_token -}}{%- endif -%}",
            "name": "phi3",
            "addGenerationPrompt": true,
            "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
        },
        "defaultCompletionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.1,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|end|>"
            ]
        },
        "completionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.1,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|end|>"
            ]
        }
    },
    {
        "id": "default-llama-3.2-1b-instruct-q8_0.gguf",
        "name": "llama-3.2-1b-instruct (Q8_0)",
        "type": "Llama",
        "size": "1.32",
        "params": "1.23",
        "isDownloaded": false,
        "downloadUrl": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-1b-instruct-q8_0.gguf?download=true",
        "hfUrl": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF",
        "progress": 0,
        "filename": "default-llama-3.2-1b-instruct-q8_0.gguf",
        "isLocal": false,
        "info_url": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF",
        "defaultChatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "chatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "defaultCompletionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        },
        "completionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        }
    },
    {
        "id": "llama-3.2-3b-instruct-q4_k_m.gguf",
        "name": "llama-3.2-3b-instruct (Q4_K)",
        "type": "Llama",
        "size": "2.02",
        "params": "3.21",
        "isDownloaded": false,
        "downloadUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF/resolve/main/llama-3.2-3b-instruct-q4_k_m.gguf?download=true",
        "hfUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF",
        "progress": 0,
        "filename": "llama-3.2-3b-instruct-q4_k_m.gguf",
        "isLocal": false,
        "info_url": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF",
        "defaultChatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "chatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "defaultCompletionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        },
        "completionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        }
    },
    {
        "id": "Llama-3.2-3B-Instruct-Q6_K.gguf",
        "name": "Llama-3.2-3B-Instruct (Q6_K)",
        "type": "Llama",
        "size": "2.64",
        "params": "3.21",
        "isDownloaded": false,
        "downloadUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf?download=true",
        "hfUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF",
        "progress": 0,
        "filename": "Llama-3.2-3B-Instruct-Q6_K.gguf",
        "isLocal": false,
        "info_url": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF",
        "defaultChatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "chatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "defaultCompletionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        },
        "completionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        }
    },
    {
        "id": "llama-3.2-3b-instruct-q8_0.gguf",
        "name": "llama-3.2-3b-instruct (q8_k)",
        "type": "Llama",
        "size": "3.42",
        "params": "3.21",
        "isDownloaded": false,
        "downloadUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-3b-instruct-q8_0.gguf?download=true",
        "hfUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF",
        "progress": 0,
        "filename": "llama-3.2-3b-instruct-q8_0.gguf",
        "isLocal": false,
        "info_url": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF",
        "defaultChatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "chatTemplate": {
            "bosToken": "<|begin_of_text|>",
            "eosToken": "<|eot_id|>",
            "addBosToken": false,
            "addEosToken": false,
            "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
            "name": "llama32",
            "addGenerationPrompt": true,
            "systemPrompt": ""
        },
        "defaultCompletionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        },
        "completionSettings": {
            "prompt": "",
            "n_predict": 500,
            "temperature": 0.5,
            "top_k": 40,
            "top_p": 0.95,
            "tfs_z": 1,
            "typical_p": 1,
            "penalty_last_n": 64,
            "penalty_repeat": 1,
            "penalty_freq": 0,
            "penalty_present": 0,
            "mirostat": 0,
            "mirostat_tau": 5,
            "mirostat_eta": 0.1,
            "penalize_nl": false,
            "seed": 0,
            "n_probs": 0,
            "stop": [
                "<|eot_id|>"
            ]
        }
    }
]
