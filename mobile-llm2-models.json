[
  {
    "id": "nidum/Nidum-3.2-3B-Uncensored-GGUF",
    "name": "Nidum-3B-Uncensored (Q4_K_M)",
    "type": "Llama",
    "size": 2167956500,
    "params": 3445654257,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF/resolve/main/model-Q4_K_M.gguf?download=true",
    "hfUrl": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF",
    "progress": 0,
    "filename": "model-Q4_K_M.gguf",
    "isLocal": false,
    "defaultChatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "nidumLlama",
      "addGenerationPrompt": true,
      "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
    },
    "chatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}...",
      "name": "nidumLlama",
      "addGenerationPrompt": true,
      "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "tfs_z": 1,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "penalize_nl": false,
      "seed": 0,
      "n_probs": 0,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "tfs_z": 1,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "penalize_nl": false,
      "seed": 0,
      "n_probs": 0,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "defaultStopWords": [
      "<|eot_id|>"
    ],
    "stopWords": [
      "<|eot_id|>"
    ],
    "hfModelFile": {
      "rfilename": "model-Q4_K_M.gguf",
      "url": "https://huggingface.co/nidum/Nidum-Llama-3.2-3B-Uncensored-GGUF",
      "size": 2167956500,
      "oid": "",
      "lfs": {
        "oid": "",
        "size": 2167956500,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  },
  {
    "id": "google/gemma-2-2b-it-GGUF",
    "name": "gemma-2-2b-it-GGUF (Q6_K)",
    "type": "Gemma",
    "description": "Question Answering, Summarization, Reasoning",
    "size": 2151393120,
    "params": 2614341888,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q6_K.gguf?download=true",
    "hfUrl": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF",
    "progress": 0,
    "filename": "gemma-2-2b-it-Q6_K.gguf",
    "isLocal": false,
    "defaultChatTemplate": {
      "bosToken": "<bos>",
      "eosToken": "<eos>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token -}}{%- if messages[0].role == 'system' -%}{%- set system_message = messages[0].content | trim + '\\n\\n' -%}{%- set messages = messages.slice(1) -%}{%- else -%}{%- set system_message = '' -%}{%- endif %}{%- for message in messages -%}{%- if (message.role == 'user') != (loop.index0 % 2 == 0) -%}{{- raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') -}}{%- endif -%}{%- if loop.index0 == 0 -%}{%- set content = system_message + message.content -%}{%- else -%}{%- set content = message.content -%}{%- endif -%}{%- if message.role == 'assistant' -%}{%- set role = 'model' -%}{%- else -%}{%- set role = message.role -%}{%- endif -%}{{- '<start_of_turn>' + role + '\\n' + (content | trim) + '<end_of_turn>\\n' -}}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<start_of_turn>model\\n' -}}{%- endif -%}",
      "name": "gemmaIt",
      "addGenerationPrompt": true,
      "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
    },
    "chatTemplate": {
      "bosToken": "<bos>",
      "eosToken": "<eos>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token -}}{%- if messages[0].role == 'system' -%}{%- set system_message = messages[0].content | trim + '\\n\\n' -%}{%- set messages = messages.slice(1) -%}{%- else -%}{%- set system_message = '' -%}{%- endif %}{%- for message in messages -%}{%- if (message.role == 'user') != (loop.index0 % 2 == 0) -%}{{- raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') -}}{%- endif -%}{%- if loop.index0 == 0 -%}{%- set content = system_message + message.content -%}{%- else -%}{%- set content = message.content -%}{%- endif -%}{%- if message.role == 'assistant' -%}{%- set role = 'model' -%}{%- else -%}{%- set role = message.role -%}{%- endif -%}{{- '<start_of_turn>' + role + '\\n' + (content | trim) + '<end_of_turn>\\n' -}}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<start_of_turn>model\\n' -}}{%- endif -%}",
      "name": "gemmaIt",
      "addGenerationPrompt": true,
      "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "defaultStopWords": [
      "<end_of_turn>"
    ],
    "stopWords": [
      "<end_of_turn>"
    ],
    "hfModelFile": {
      "rfilename": "gemma-2-2b-it-Q6_K.gguf",
      "url": "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q6_K.gguf",
      "size": 2151393120,
      "oid": "72f2510b5868d1141617aa16cfc4c4a61ec77262",
      "lfs": {
        "oid": "f82c5c2230a8b452221706461eb93203443373625d96a05912d4f96c845c2775",
        "size": 2151393120,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  },
  {
    "id": "Phi-3.5-mini-instruct.Q4_K_M.gguf",
    "name": "Phi-3.5 mini 4k instruct (Q4_K_M)",
    "type": "Phi",
    "description": "Reasoning (code & math). Multilingual",
    "size": 2393232608,
    "params": 3821079648,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct.Q4_K_M.gguf",
    "hfUrl": "https://huggingface.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF",
    "progress": 0,
    "filename": "Phi-3.5-mini-instruct.Q4_K_M.gguf",
    "isLocal": false,
    "defaultChatTemplate": {
      "bosToken": "<s>",
      "eosToken": "<|endoftext|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{%- for message in messages -%}{%- if message.role == 'system' -%}{{- '<|system|>\\n' + message.content | trim + '<|end|>\\n' -}}{%- elif message.role == 'user' -%}{{- '<|user|>\\n' + message.content | trim + '<|end|>\\n' -}}{%- elif message.role == 'assistant' -%}{{- '<|assistant|>\\n' + message.content | trim + '<|end|>\\n' -}}{%- endif -%}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<|assistant|>\\n' -}}{%- else -%}{{- eos_token -}}{%- endif -%}",
      "name": "phi3",
      "addGenerationPrompt": true,
      "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
    },
    "chatTemplate": {
      "bosToken": "<s>",
      "eosToken": "<|endoftext|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{%- for message in messages -%}{%- if message.role == 'system' -%}{{- '<|system|>\\n' + message.content | trim + '<|end|>\\n' -}}{%- elif message.role == 'user' -%}{{- '<|user|>\\n' + message.content | trim + '<|end|>\\n' -}}{%- elif message.role == 'assistant' -%}{{- '<|assistant|>\\n' + message.content | trim + '<|end|>\\n' -}}{%- endif -%}{%- endfor -%}{%- if add_generation_prompt -%}{{- '<|assistant|>\\n' -}}{%- else -%}{{- eos_token -}}{%- endif -%}",
      "name": "phi3",
      "addGenerationPrompt": true,
      "systemPrompt": "You are a helpful conversational chat assistant. You are precise, concise, and casual."
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.1,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.1,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "defaultStopWords": [
      "<|end|>"
    ],
    "stopWords": [
      "<|end|>"
    ],
    "hfModelFile": {
      "rfilename": "Phi-3.5-mini-instruct.Q4_K_M.gguf",
      "url": "https://huggingface.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct.Q4_K_M.gguf",
      "size": 2393232608,
      "oid": "a2b0f35b7504ba395e886fadd5ebc61236b9f5ec",
      "lfs": {
        "oid": "3f68916e850b107d8641d18bcd5548f0d66beef9e0a9077fe84ef28943eb7e88",
        "size": 2393232608,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  },
  {
    "id": "default-llama-3.2-1b-instruct-q8_0.gguf",
    "name": "llama-3.2-1b-instruct (Q8_0)",
    "type": "Llama",
    "description": "Instruction following, Summarization, Rewriting",
    "size": 1321079200,
    "params": 1235814432,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-1b-instruct-q8_0.gguf",
    "hfUrl": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF",
    "progress": 0,
    "filename": "llama-3.2-1b-instruct-q8_0.gguf",
    "isLocal": false,
    "defaultChatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "chatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "defaultStopWords": [
      "<|eot_id|>"
    ],
    "stopWords": [
      "<|eot_id|>"
    ],
    "hfModelFile": {
      "rfilename": "llama-3.2-1b-instruct-q8_0.gguf",
      "url": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-1b-instruct-q8_0.gguf",
      "size": 1321079200,
      "oid": "4d5402369568f0bd157d8454270821341e833722",
      "lfs": {
        "oid": "ba345c83bf5cc679c653b853c46517eea5a34f03ed2205449db77184d9ae62a9",
        "size": 1321079200,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  },
  {
    "id": "llama-3.2-3b-instruct-q4_k_m.gguf",
    "name": "llama-3.2-3b-instruct (Q4_K)",
    "type": "Llama",
    "size": 2167956500,
    "params": 3445654257,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF/resolve/main/llama-3.2-3b-instruct-q4_k_m.gguf?download=true",
    "hfUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF",
    "progress": 0,
    "filename": "llama-3.2-3b-instruct-q4_k_m.gguf",
    "isLocal": false,
    "info_url": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF",
    "defaultChatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "chatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "tfs_z": 1,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "penalize_nl": false,
      "seed": 0,
      "n_probs": 0,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "tfs_z": 1,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "penalize_nl": false,
      "seed": 0,
      "n_probs": 0,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "defaultStopWords": [
      "<|eot_id|>"
    ],
    "stopWords": [
      "<|eot_id|>"
    ],
    "hfModelFile": {
      "rfilename": "llama-3.2-3b-instruct-q4_k_m.gguf",
      "url": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q4_K_M-GGUF",
      "size": 2167956500,
      "oid": "",
      "lfs": {
        "oid": "",
        "size": 2167956500,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  },
  {
    "id": "Llama-3.2-3B-Instruct-Q6_K.gguf",
    "name": "Llama-3.2-3B-Instruct (Q6_K)",
    "type": "Llama",
    "description": "Instruction following, Summarization, Rewriting",
    "size": 2643853856,
    "params": 3212749888,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf",
    "hfUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF",
    "progress": 0,
    "filename": "Llama-3.2-3B-Instruct-Q6_K.gguf",
    "isLocal": false,
    "defaultChatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "chatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "min_p": 0.05,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "seed": -1,
      "n_probs": 0,
      "stop": [
        "</s>"
      ]
    },
    "defaultStopWords": [
      "<|eot_id|>"
    ],
    "stopWords": [
      "<|eot_id|>"
    ],
    "hfModelFile": {
      "rfilename": "Llama-3.2-3B-Instruct-Q6_K.gguf",
      "url": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf",
      "size": 2643853856,
      "oid": "47d12cf8883aaa6a6cd0b47975cc026980a3af9d",
      "lfs": {
        "oid": "1771887c15fc3d327cfee6fd593553b2126e88834bf48eae50e709d3f70dd998",
        "size": 2643853856,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  },
  {
    "id": "llama-3.2-3b-instruct-q8_0.gguf",
    "name": "llama-3.2-3b-instruct (q8_k)",
    "type": "Llama",
    "size": 3671384045,
    "params": 3445654257,
    "isDownloaded": false,
    "downloadUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-3b-instruct-q8_0.gguf?download=true",
    "hfUrl": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF",
    "progress": 0,
    "filename": "llama-3.2-3b-instruct-q8_0.gguf",
    "isLocal": false,
    "defaultChatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "chatTemplate": {
      "bosToken": "<|begin_of_text|>",
      "eosToken": "<|eot_id|>",
      "addBosToken": false,
      "addEosToken": false,
      "chatTemplate": "{{- bos_token }}{%- if custom_tools is defined %}{%- set tools = custom_tools %}{%- endif %}{%- if tools_in_user_message is not defined %}{%- set tools_in_user_message = true %}{%- endif %}{%- if date_string is not defined %}{%- if strftime_now is defined %}{%- set date_string = strftime_now('%d %b %Y') %}{%- else %}{%- set date_string = '26 Jul 2024' %}{%- endif %}{%- endif %}{%- if tools is not defined %}{%- set tools = none %}{%- endif %}{#- This block extracts the system message, so we can slot it into the right place. #}{%- if messages[0]['role'] == 'system' %}{%- set system_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{%- set system_message = '' %}{%- endif %}{#- System message #}{{- '<|start_header_id|>system<|end_header_id|>\n\n' }}{%- if tools is not none %}{{- 'Environment: ipython\n' }}{%- endif %}{{- 'Cutting Knowledge Date: December 2023\n' }}{{- 'Today Date: ' + date_string + '\n\n' }}{%- if tools is not none and not tools_in_user_message %}{{- 'You have access to the following functions. To call a function, please respond with JSON for a function call.' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{%- endif %}{{- system_message }}{{- '<|eot_id|>' }}{# Custom tools are passed in a user message with some extra guidance #}{%- if tools_in_user_message and tools is not none %}{#- Extract the first user message so we can plug it in here #}{%- if messages.length != 0 %}{%- set first_user_message = messages[0]['content'] | trim %}{%- set messages = messages.slice(1) %}{%- else %}{{- raise_exception('Cannot put tools in the first user message when there is no first user message!') }}{%- endif %}{{- '<|start_header_id|>user<|end_header_id|>\n\n' }}{{- 'Given the following functions, please respond with a JSON for a function call ' }}{{- 'with its proper arguments that best answers the given prompt.\n\n' }}{{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}{{- 'Do not use variables.\n\n' }}{%- for t in tools %}{{- t | dump(4) }}{{- '\n\n' }}{%- endfor %}{{- first_user_message + '<|eot_id|>' }}{%- endif %}{%- for message in messages %}{%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}{{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] | trim + '<|eot_id|>' }}{%- elif 'tool_calls' in message %}{%- if message.tool_calls.length != 1 %}{{- raise_exception('This model only supports single tool-calls at once!') }}{%- endif %}{%- set tool_call = message.tool_calls[0].function %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{{- '{\"name\": \"' + tool_call.name + '\", ' }}{{- '\"parameters\": ' }}{{- tool_call.arguments | dump }}{{- '}' }}{{- '<|eot_id|>' }}{%- elif message.role == 'tool' or message.role == 'ipython' %}{{- '<|start_header_id|>ipython<|end_header_id|>\n\n' }}{%- if message.content is mapping or message.content is iterable %}{{- message.content | dump }}{%- else %}{{- message.content }}{%- endif %}{{- '<|eot_id|>' }}{%- endif %}{%- endfor %}{%- if add_generation_prompt %}{{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{%- endif %}",
      "name": "llama32",
      "addGenerationPrompt": true,
      "systemPrompt": ""
    },
    "defaultCompletionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "tfs_z": 1,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "penalize_nl": false,
      "seed": 0,
      "n_probs": 0,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "completionSettings": {
      "prompt": "",
      "n_predict": 500,
      "temperature": 0.5,
      "top_k": 40,
      "top_p": 0.95,
      "tfs_z": 1,
      "typical_p": 1,
      "penalty_last_n": 64,
      "penalty_repeat": 1,
      "penalty_freq": 0,
      "penalty_present": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "penalize_nl": false,
      "seed": 0,
      "n_probs": 0,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "defaultStopWords": [
      "<|eot_id|>"
    ],
    "stopWords": [
      "<|eot_id|>"
    ],
    "hfModelFile": {
      "rfilename": "llama-3.2-3b-instruct-q8_0.gguf",
      "url": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF",
      "size": 3671384045,
      "oid": "",
      "lfs": {
        "oid": "",
        "size": 3671384045,
        "pointerSize": 135
      },
      "canFitInStorage": true
    }
  }
]
